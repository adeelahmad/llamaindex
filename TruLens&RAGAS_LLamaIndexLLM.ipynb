{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LzzdSNWpcylE"
      },
      "source": [
        "### Libraries Required"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iA_CRvu4cylH"
      },
      "outputs": [],
      "source": [
        "# pip install llama_index html2text trulens_eval"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xLlLKNt2cylJ"
      },
      "source": [
        "### Adding API keys\n",
        "We require OPENAI API Key for using GPT model & Evaluations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2AXkcHgVcylJ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"[REPLACE_WITH_YOUR_OPENAI_API_KEY]”"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bSoSlRavcylK"
      },
      "source": [
        "### Import from LlamaIndex and TruLens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HlO-driMcylK"
      },
      "outputs": [],
      "source": [
        "from trulens_eval import Feedback, Tru, TruLlama\n",
        "from trulens_eval.feedback import Groundedness\n",
        "from trulens_eval.feedback.provider.openai import OpenAI\n",
        "\n",
        "tru = Tru()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xA7hfto5cylL"
      },
      "source": [
        "### Creating a Simple LLM Application\n",
        "\n",
        "This example uses LlamaIndex which internally uses an OpenAI LLM."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lft3y0MJcylL"
      },
      "outputs": [],
      "source": [
        "from llama_index import VectorStoreIndex\n",
        "from llama_index.readers.web import SimpleWebPageReader\n",
        "\n",
        "documents = SimpleWebPageReader(\n",
        "    html_to_text=True\n",
        ").load_data([\"https://mlds.analyticsindiamag.com/\"])\n",
        "index = VectorStoreIndex.from_documents(documents)\n",
        "\n",
        "query_engine = index.as_query_engine()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ilbEQnOcylM"
      },
      "source": [
        "### Sending first request"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NaI45qjqcylM",
        "outputId": "07372c2b-c6a1-43b0-ae14-9a63b52d4879"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MLDS2024 is scheduled to take place on February 1 to 2, 2024. The conference will be held in Bengaluru, India.\n"
          ]
        }
      ],
      "source": [
        "response = query_engine.query(\"When is MLDS2024 & it's in which city?\")\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A2yy17hIcylN"
      },
      "source": [
        "### Initialize Feedback Function(s)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aeajiOvzcylN",
        "outputId": "9c345fa3-d0a2-454d-f32a-234e44011f63"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ In groundedness_measure_with_cot_reasons, input source will be set to __record__.app.query.rets.source_nodes[:].node.text.collect() .\n",
            "✅ In groundedness_measure_with_cot_reasons, input statement will be set to __record__.main_output or `Select.RecordOutput` .\n",
            "✅ In relevance, input prompt will be set to __record__.main_input or `Select.RecordInput` .\n",
            "✅ In relevance, input response will be set to __record__.main_output or `Select.RecordOutput` .\n",
            "✅ In qs_relevance, input question will be set to __record__.main_input or `Select.RecordInput` .\n",
            "✅ In qs_relevance, input statement will be set to __record__.app.query.rets.source_nodes[:].node.text .\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Initialize provider class\n",
        "openai = OpenAI()\n",
        "\n",
        "grounded = Groundedness(groundedness_provider=OpenAI())\n",
        "\n",
        "# Define a groundedness feedback function\n",
        "f_groundedness = Feedback(grounded.groundedness_measure_with_cot_reasons).on(\n",
        "    TruLlama.select_source_nodes().node.text.collect()\n",
        "    ).on_output(\n",
        "    ).aggregate(grounded.grounded_statements_aggregator)\n",
        "\n",
        "# Question/answer relevance between overall question and answer.\n",
        "f_qa_relevance = Feedback(openai.relevance).on_input_output()\n",
        "\n",
        "# Question/statement relevance between question and each context chunk.\n",
        "f_qs_relevance = Feedback(openai.qs_relevance).on_input().on(\n",
        "    TruLlama.select_source_nodes().node.text\n",
        "    ).aggregate(np.mean)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FawvZDMUcylO"
      },
      "source": [
        "### Instrument app for logging with TruLens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lTHUV1x6cylO"
      },
      "outputs": [],
      "source": [
        "tru_query_engine_recorder = TruLlama(query_engine,\n",
        "    app_id='LlamaIndex_App1',\n",
        "    feedbacks=[f_groundedness, f_qa_relevance, f_qs_relevance])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uW2vGmSbcylO"
      },
      "outputs": [],
      "source": [
        "# or as context manager\n",
        "with tru_query_engine_recorder as recording:\n",
        "    query_engine.query(\"When is MLDS2024 & it's in which city?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JmBHFKfbcylO"
      },
      "source": [
        "### Streamlit Dashboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NNObnS5EcylO"
      },
      "outputs": [],
      "source": [
        "tru.run_dashboard() # open a local streamlit app to explore\n",
        "\n",
        "#tru.stop_dashboard() # stop if needed"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x39K1L62cylP"
      },
      "source": [
        "### RAGAS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3e4eIgYWcylP"
      },
      "outputs": [],
      "source": [
        "#! pip install ragas\n",
        "\n",
        "eval_questions = [\n",
        "    \"When is MLDS2024 & it's in which city?\", \"What is MLDS?\"\n",
        "]\n",
        "\n",
        "eval_answers = [\n",
        "    \"MLDS2024 is scheduled to take place on February 15 to 18, 2024. The conference will be held in Delhi, India.\",\n",
        "    \"MLDS is a spaceship.\"\n",
        "]\n",
        "\n",
        "eval_answers = [[a] for a in eval_answers]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UaMzZgDxcylP"
      },
      "outputs": [],
      "source": [
        "from ragas.metrics import (\n",
        "    faithfulness,\n",
        "    answer_relevancy,\n",
        "    context_precision,\n",
        "    context_recall,\n",
        ")\n",
        "from ragas.metrics.critique import harmfulness\n",
        "\n",
        "metrics = [\n",
        "    faithfulness,\n",
        "    answer_relevancy,\n",
        "    context_precision,\n",
        "    context_recall,\n",
        "    harmfulness,\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KYLien_TcylP",
        "outputId": "c071fee8-53df-497e-98e1-8b943ac8d5f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nest-asyncio in /Users/sachintripathi/Library/Python/3.11/lib/python/site-packages (1.5.8)\n",
            "evaluating with [faithfulness]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:15<00:00, 15.15s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "evaluating with [answer_relevancy]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:06<00:00,  6.91s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "evaluating with [context_precision]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:02<00:00,  2.51s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "evaluating with [context_recall]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:04<00:00,  4.35s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "evaluating with [harmfulness]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:03<00:00,  3.67s/it]\n"
          ]
        }
      ],
      "source": [
        "! pip install nest-asyncio\n",
        "import nest_asyncio\n",
        "nest_asyncio.apply()\n",
        "\n",
        "from ragas.llama_index import evaluate\n",
        "\n",
        "result = evaluate(query_engine, metrics, eval_questions, eval_answers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wLinHO2lcylP",
        "outputId": "308008f7-e798-4abd-a7fb-dc99b00d3255"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'faithfulness': 1.0000, 'answer_relevancy': 0.9530, 'context_precision': 0.5000, 'context_recall': 0.2500, 'harmfulness': 0.0000}\n"
          ]
        }
      ],
      "source": [
        "print(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gZGkSrbXcylP"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.11.4 ('agents')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "7d153714b979d5e6d08dd8ec90712dd93bff2c9b6c1f0c118169738af3430cd4"
      }
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}